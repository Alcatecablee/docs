# 3-Agent Parallel Architecture Roadmap

**Project**: ViberDoc AI Agent System Evolution  
**Goal**: Transform linear 4-stage pipeline â†’ Parallel 3-agent specialist system  
**Timeline**: 4 weeks (MVP in 2 weeks)  
**Expected Improvements**: 3x faster, 40% better quality, same cost

---

## ðŸŽ¯ Executive Summary

### Current State (Linear Pipeline)
```
User Request â†’ Stage 1 (Discovery) â†’ Stage 2 (Extract) â†’ Stage 3 (Synthesis) â†’ Stage 4 (Validate)
Time: ~90 seconds | LLM Calls: 4 sequential | Quality Score: ~75/100
```

### Target State (Parallel Agent System)
```
User Request â†’ [Research Agent || Code Agent || Structure Agent] â†’ Synthesis â†’ Critic Agent â†’ Output
Time: ~45 seconds | LLM Calls: 4 (3 parallel + 1 sequential) | Quality Score: ~90/100
```

### Key Benefits
- **âš¡ 50% faster**: Parallel execution vs sequential
- **ðŸ“ˆ 20% better quality**: Specialized agents with focused expertise
- **ðŸ’° Same cost**: 4 LLM calls total (just reorganized)
- **ðŸ”„ Reuses infrastructure**: BullMQ, multi-provider routing, quality scoring

---

## ðŸ“‹ Phase 1: Foundation (Week 1)

### 1.1 Agent Interface & Base Class

**Deliverable**: Abstract agent base class that all agents inherit from

```typescript
// server/agents/base-agent.ts
abstract class BaseAgent {
  abstract name: string;
  abstract execute(context: AgentContext): Promise<AgentResult>;
  
  // Built-in retry, timeout, provider failover
  protected async callLLM(prompt: string, options?: LLMOptions): Promise<string>;
  protected async validateOutput(output: any, schema: z.ZodSchema): Promise<boolean>;
}
```

**Tasks**:
- [ ] Create `server/agents/` directory
- [ ] Define `AgentContext` and `AgentResult` types
- [ ] Implement base agent with LLM routing integration
- [ ] Add timeout/retry logic
- [ ] Write unit tests

**Dependencies**: Existing multi-provider LLM system

---

### 1.2 Research Agent (Specialist #1)

**Purpose**: Gather external knowledge from Stack Overflow, GitHub, Reddit, YouTube, forums

**Deliverable**: `ResearchAgent` that finds real-world usage patterns, issues, solutions

```typescript
// server/agents/research-agent.ts
class ResearchAgent extends BaseAgent {
  async execute(context: AgentContext): Promise<ResearchResult> {
    const queries = this.generateSearchQueries(context.product);
    
    const [stackOverflow, github, reddit, youtube] = await Promise.all([
      this.searchStackOverflow(queries),
      this.searchGitHub(queries),
      this.searchReddit(queries),
      this.searchYouTube(queries)
    ]);
    
    return {
      issues: this.extractCommonIssues(stackOverflow, github),
      solutions: this.extractSolutions(stackOverflow),
      useCases: this.extractUseCases(reddit, youtube),
      communityInsights: this.analyzeSentiment(reddit)
    };
  }
}
```

**Tasks**:
- [ ] Implement search query generation
- [ ] Integrate Stack Overflow API
- [ ] Integrate GitHub search API
- [ ] Integrate Reddit API
- [ ] Parse YouTube transcripts
- [ ] Extract and score relevance
- [ ] Cache results (Redis)
- [ ] Write integration tests

**Output Schema**:
```typescript
interface ResearchResult {
  issues: Array<{ title: string; votes: number; solution: string }>;
  solutions: Array<{ approach: string; code?: string; popularity: number }>;
  useCases: Array<{ scenario: string; source: string }>;
  communityInsights: { sentiment: string; popularityTrend: string };
}
```

---

### 1.3 Code Agent (Specialist #2)

**Purpose**: Find real, working code examples from GitHub, official repos, docs

**Deliverable**: `CodeAgent` that provides tested, real-world code snippets

```typescript
// server/agents/code-agent.ts
class CodeAgent extends BaseAgent {
  async execute(context: AgentContext): Promise<CodeResult> {
    const [officialExamples, githubExamples] = await Promise.all([
      this.findOfficialExamples(context.repoUrl),
      this.searchGitHubCode(context.product, context.language)
    ]);
    
    return {
      quickStart: this.extractQuickStart(officialExamples),
      apiExamples: this.extractAPIUsage(officialExamples, githubExamples),
      integrationExamples: this.extractIntegrations(githubExamples),
      commonPatterns: this.identifyPatterns(githubExamples)
    };
  }
}
```

**Tasks**:
- [ ] GitHub code search integration
- [ ] Parse README examples
- [ ] Extract code from issues/discussions
- [ ] Validate code syntax
- [ ] Score code quality (stars, forks, recency)
- [ ] Deduplicate similar examples
- [ ] Write integration tests

**Output Schema**:
```typescript
interface CodeResult {
  quickStart: { language: string; code: string; description: string }[];
  apiExamples: { method: string; example: string; explanation: string }[];
  integrationExamples: { framework: string; code: string }[];
  commonPatterns: { pattern: string; usage: string }[];
}
```

---

### 1.4 Structure Agent (Specialist #3)

**Purpose**: Analyze sitemap, README, docs structure to create optimal outline

**Deliverable**: `StructureAgent` that generates enterprise-grade doc outline

```typescript
// server/agents/structure-agent.ts
class StructureAgent extends BaseAgent {
  async execute(context: AgentContext): Promise<StructureResult> {
    const [sitemap, readme, docsPages] = await Promise.all([
      this.parseSitemap(context.url),
      this.parseREADME(context.repoUrl),
      this.crawlDocsPages(context.url + '/docs')
    ]);
    
    return {
      outline: this.generateOutline(sitemap, readme, docsPages),
      navigation: this.extractNavigation(docsPages),
      contentGaps: this.identifyGaps(sitemap, readme),
      recommendedSections: this.recommendSections(context.productType)
    };
  }
}
```

**Tasks**:
- [ ] Sitemap.xml parser
- [ ] README structure analyzer
- [ ] Docs page crawler
- [ ] Navigation hierarchy extractor
- [ ] Gap detection algorithm
- [ ] Section recommendation engine
- [ ] Write integration tests

**Output Schema**:
```typescript
interface StructureResult {
  outline: DocumentSection[];
  navigation: NavigationItem[];
  contentGaps: string[];
  recommendedSections: string[];
}
```

---

## ðŸ“‹ Phase 2: Orchestration (Week 2)

### 2.1 Agent Orchestrator

**Purpose**: Coordinate parallel agent execution and merge results

**Deliverable**: `AgentOrchestrator` that runs agents in parallel and handles failures

```typescript
// server/agents/orchestrator.ts
class AgentOrchestrator {
  async executeParallel(
    context: AgentContext
  ): Promise<CombinedAgentResults> {
    const startTime = Date.now();
    
    try {
      // Execute all 3 agents in parallel with timeout
      const [research, code, structure] = await Promise.all([
        this.executeWithTimeout(researchAgent, context, 30000),
        this.executeWithTimeout(codeAgent, context, 30000),
        this.executeWithTimeout(structureAgent, context, 30000)
      ]);
      
      return {
        research,
        code,
        structure,
        executionTime: Date.now() - startTime,
        status: 'success'
      };
    } catch (error) {
      // Graceful degradation: use whatever completed
      return this.handlePartialFailure(error);
    }
  }
  
  private async executeWithTimeout(
    agent: BaseAgent,
    context: AgentContext,
    timeout: number
  ): Promise<AgentResult> {
    return Promise.race([
      agent.execute(context),
      this.timeout(timeout, agent.name)
    ]);
  }
}
```

**Tasks**:
- [ ] Implement parallel execution
- [ ] Add timeout handling per agent
- [ ] Implement graceful degradation
- [ ] Result merging logic
- [ ] Error recovery strategies
- [ ] Monitoring/metrics integration
- [ ] Write integration tests

---

### 2.2 Update Documentation Generator

**Purpose**: Integrate agent orchestrator into existing pipeline

**Before**:
```typescript
async function generateDocumentationPipeline(url: string) {
  const stage1 = await discovery(url);       // 30s
  const stage2 = await extract(stage1);      // 20s
  const stage3 = await synthesize(stage2);   // 30s
  const stage4 = await validate(stage3);     // 10s
  return stage4;  // Total: 90s
}
```

**After**:
```typescript
async function generateDocumentationPipeline(url: string) {
  // Run 3 agents in parallel (replaces stages 1-2)
  const agentResults = await orchestrator.executeParallel({
    url,
    product: extractProductName(url),
    repoUrl: findGitHubRepo(url)
  });  // 30s (parallel)
  
  // Synthesize using combined agent results
  const stage3 = await synthesize(agentResults);  // 20s
  
  // Validate
  const stage4 = await validate(stage3);  // 10s
  
  return stage4;  // Total: 60s (33% faster!)
}
```

**Tasks**:
- [ ] Update `server/generator.ts`
- [ ] Modify synthesis stage to accept agent results
- [ ] Update progress tracking (3 parallel tasks)
- [ ] Preserve backward compatibility
- [ ] Add feature flag for rollback
- [ ] Write integration tests

---

## ðŸ“‹ Phase 3: Quality Enhancement (Week 3)

### 3.1 Critic Agent (Quality Validator)

**Purpose**: Review generated documentation and identify gaps/issues

**Deliverable**: `CriticAgent` that scores and suggests improvements

```typescript
// server/agents/critic-agent.ts
class CriticAgent extends BaseAgent {
  async execute(
    documentation: Documentation,
    agentResults: CombinedAgentResults
  ): Promise<CriticResult> {
    const scores = await this.scoreDocumentation(documentation);
    
    return {
      overallScore: scores.overall,
      dimensionScores: {
        completeness: scores.completeness,
        accuracy: scores.accuracy,
        clarity: scores.clarity,
        codeQuality: scores.codeQuality,
        seoOptimization: scores.seo
      },
      gaps: this.identifyGaps(documentation, agentResults),
      suggestions: this.generateSuggestions(scores),
      needsRefinement: scores.overall < 85
    };
  }
}
```

**Tasks**:
- [ ] Implement multi-dimension scoring
- [ ] Gap detection algorithm
- [ ] Suggestion generation
- [ ] Integration with quality validation
- [ ] Write unit tests

---

### 3.2 Auto-Refinement Loop

**Purpose**: Automatically improve docs when critic score is low

```typescript
async function generateWithRefinement(url: string): Promise<Documentation> {
  let attempt = 0;
  const maxAttempts = 2;
  
  while (attempt < maxAttempts) {
    const agentResults = await orchestrator.executeParallel({ url });
    const documentation = await synthesize(agentResults);
    const critique = await criticAgent.execute(documentation, agentResults);
    
    if (critique.overallScore >= 85 || attempt === maxAttempts - 1) {
      return documentation;
    }
    
    // Refine using critic suggestions
    agentResults.refinementContext = critique.suggestions;
    attempt++;
  }
}
```

**Tasks**:
- [ ] Implement refinement loop
- [ ] Add circuit breaker (max 2 attempts)
- [ ] Track refinement metrics
- [ ] Write integration tests

---

## ðŸ“‹ Phase 4: Advanced Features (Week 4)

### 4.1 Agent Debate Mechanism (Optional)

**Purpose**: Let agents challenge each other's findings

```typescript
class AgentDebater {
  async debate(
    research: ResearchResult,
    code: CodeResult
  ): Promise<DebateResult> {
    // Research says: "Most popular approach is X"
    // Code says: "But only 5% of repos actually use X"
    
    const conflicts = this.detectConflicts(research, code);
    const resolutions = await this.resolveConflicts(conflicts);
    
    return {
      agreedFacts: this.extractConsensus(research, code),
      warnings: this.generateWarnings(conflicts),
      recommendations: resolutions
    };
  }
}
```

**Tasks**:
- [ ] Implement conflict detection
- [ ] Build resolution logic
- [ ] Generate warnings
- [ ] Write tests

---

### 4.2 Performance Optimization

**Tasks**:
- [ ] Cache agent results (1 hour TTL)
- [ ] Implement result deduplication
- [ ] Optimize parallel batching
- [ ] Add request coalescing
- [ ] Monitor P95 latency
- [ ] Set up alerts

---

### 4.3 Monitoring & Observability

**Tasks**:
- [ ] Agent execution metrics
- [ ] Success/failure rates per agent
- [ ] Latency tracking
- [ ] Cost tracking per agent
- [ ] Quality score trends
- [ ] Error rate monitoring

---

## ðŸŽ¯ Success Metrics

### Performance Targets
| Metric | Current | Target | Measurement |
|--------|---------|--------|-------------|
| Generation Time | 90s | 60s | P95 latency |
| Quality Score | 75/100 | 90/100 | Average |
| Success Rate | 85% | 95% | Successful completions |
| Cost per Doc | $0.25 | $0.30 | LLM API costs |

### Quality Dimensions
- **Completeness**: All sections present, no gaps
- **Accuracy**: Real code examples, validated info
- **Clarity**: Easy to read, well-structured
- **SEO**: Optimized titles, descriptions, keywords
- **Code Quality**: Working examples, best practices

---

## ðŸš¨ Risks & Mitigations

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Agent timeout | High | Medium | 30s timeout per agent, graceful degradation |
| Increased costs | Medium | Low | Use free providers first, monitor usage |
| Quality regression | High | Low | Keep old pipeline, feature flag rollback |
| Complexity increase | Medium | High | Thorough testing, comprehensive docs |

---

## ðŸ”„ Rollback Plan

1. Feature flag: `ENABLE_AGENT_SYSTEM=false` â†’ revert to old pipeline
2. Database compatibility: No schema changes required
3. API compatibility: No breaking changes to endpoints
4. Gradual rollout: A/B test 10% â†’ 50% â†’ 100%

---

## ðŸ“š Technical Architecture

### File Structure
```
server/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base-agent.ts           # Abstract base class
â”‚   â”œâ”€â”€ research-agent.ts       # External knowledge gathering
â”‚   â”œâ”€â”€ code-agent.ts           # Code example finder
â”‚   â”œâ”€â”€ structure-agent.ts      # Outline generator
â”‚   â”œâ”€â”€ critic-agent.ts         # Quality validator
â”‚   â”œâ”€â”€ orchestrator.ts         # Parallel execution coordinator
â”‚   â”œâ”€â”€ types.ts                # Shared types
â”‚   â””â”€â”€ __tests__/              # Unit & integration tests
â”œâ”€â”€ generator.ts                 # Updated pipeline (integrates orchestrator)
â””â”€â”€ utils/
    â”œâ”€â”€ agent-monitor.ts         # Metrics & monitoring
    â””â”€â”€ agent-cache.ts          # Result caching
```

### Integration Points
1. **Multi-provider LLM**: Reuse existing `server/llm-router.ts`
2. **BullMQ**: Orchestrate long-running agent tasks
3. **Redis**: Cache agent results
4. **Quality scoring**: Integrate with existing validation
5. **Progress tracking**: Update to show 3 parallel tasks

---

## ðŸŽ“ Testing Strategy

### Unit Tests
- Each agent class (research, code, structure, critic)
- Orchestrator coordination logic
- Error handling & timeout scenarios

### Integration Tests
- Full pipeline with mocked LLM responses
- Agent result merging
- Graceful degradation scenarios
- Cost tracking accuracy

### E2E Tests
- Real documentation generation
- Quality score validation
- Performance benchmarking

---

## ðŸ“… Implementation Schedule

### Week 1: Foundation
- Day 1-2: Base agent class, types, infrastructure
- Day 3-4: Research agent
- Day 5-7: Code agent, Structure agent

### Week 2: Integration
- Day 8-9: Orchestrator
- Day 10-11: Update generator pipeline
- Day 12-14: Testing & bug fixes

### Week 3: Quality
- Day 15-16: Critic agent
- Day 17-18: Auto-refinement loop
- Day 19-21: Performance optimization

### Week 4: Polish
- Day 22-23: Monitoring & alerts
- Day 24-25: Documentation
- Day 26-28: A/B testing & gradual rollout

---

## ðŸŽ‰ Launch Checklist

- [ ] All agents tested independently
- [ ] Orchestrator handles failures gracefully
- [ ] Performance meets targets (60s generation)
- [ ] Quality meets targets (90/100 score)
- [ ] Costs stay within budget ($0.30/doc)
- [ ] Monitoring dashboards live
- [ ] Feature flag ready for rollback
- [ ] Documentation updated
- [ ] Team trained on new system
- [ ] A/B test configured (10% traffic)

---

## ðŸ“– Appendix: Comparison Table

| Feature | Old Pipeline | New Agent System |
|---------|--------------|------------------|
| Architecture | 4 sequential stages | 3 parallel agents + synthesis |
| Execution | Linear | Parallel |
| Time | ~90 seconds | ~60 seconds |
| LLM Calls | 4 sequential | 4 (3 parallel + 1) |
| Specialization | General purpose | Role-specific |
| Quality | 75/100 | 90/100 |
| Failure Handling | All-or-nothing | Graceful degradation |
| Code Examples | Generic | Real GitHub code |
| Community Insights | Limited | Rich (SO, Reddit, forums) |
| Auto-refinement | No | Yes (critic loop) |
| Monitoring | Basic | Per-agent metrics |

---

**Status**: Ready to implement  
**Owner**: Engineering team  
**Last Updated**: 2025-10-31  
**Next Review**: After Phase 1 completion
